{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the name of the experiment folder in logs/, .e.g 'SR1'\n",
    "EXPERIMENT = \"SR2\"\n",
    "ECC = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b884982-520f-4d73-9e58-1d5114b1c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import traceback\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import NaN\n",
    "from functions import * # import functions from the .py file\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams[\"figure.figsize\"] = 16, 4\n",
    "\n",
    "PAYLOADSIZE = 14\n",
    "\n",
    "if PAYLOADSIZE % 2 != 0:\n",
    "    print(\"Alarm! the payload size is not even.\")\n",
    "NUM_16RND = (PAYLOADSIZE-2)//2 # how many 16 bits random number included in each frame\n",
    "MAX_SEQ = 256 # (decimal) maximum seq number defined by the length of the seq, the length of seq is 1B\n",
    "\n",
    "clock = 125\n",
    "logdir = f\"./logs/{EXPERIMENT}\"\n",
    "experiments_data = []\n",
    "\n",
    "print(f\"Reading experiment folder '{logdir}'...\")\n",
    "for idx, path in enumerate(glob.glob(f\"{logdir}/*\")):\n",
    "    log_paths = []\n",
    "    # We have multiple log files for this configuration and we want to \n",
    "    # read them all and get the average. \n",
    "    if os.path.isdir(path):\n",
    "        log_paths = glob.glob(f\"{path}/*.txt\")\n",
    "    elif path.endswith(\".txt\"):\n",
    "        log_paths.append(path)\n",
    "\n",
    "    if len(log_paths) == 0:\n",
    "        continue\n",
    "\n",
    "    dfs = [readfile(f) for f in log_paths]\n",
    "    filename = os.path.basename(path)\n",
    "    params = filename.removesuffix(\".txt\").split(\"_\")\n",
    "    experiments_data.append({\n",
    "        \"file\": filename,\n",
    "        \"d2\":int(params[0]), # tag to receiver (cm)\n",
    "        \"d1\":int(params[1]), # carrier to tag (cm)\n",
    "        \"a\": int(params[2]),\n",
    "        \"b\": int(params[3]),\n",
    "        \"baud\": int(params[4].replace('k', '000')),\n",
    "        \"delta_fsk\": ((clock/int(params[3]) - clock/int(params[2])) * 1000)/2, # khz\n",
    "        \"file_delay_s\": None,\n",
    "        \"bit_reliability\": None,\n",
    "        \"dis_metric\": None,\n",
    "        \"etx\": None,\n",
    "        \"avg_rssi\": None,\n",
    "        \"samples\": len(dfs),\n",
    "        \"error\": False,\n",
    "        \"dfs\": dfs,\n",
    "    })\n",
    "\n",
    "def avg(lst):\n",
    "    if len(lst) == 0:\n",
    "        return 0\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "def analyze():\n",
    "    errors = []\n",
    "    experiments = pd.DataFrame()\n",
    "    for idx, data in enumerate(experiments_data):\n",
    "        etx_lst = []\n",
    "        file_delay_s_lst = []\n",
    "        bit_reliability_lst = []\n",
    "        dis_metric_lst = []\n",
    "        rssi_lst = []\n",
    "        experiment_error = False\n",
    "\n",
    "        for df in data[\"dfs\"]:\n",
    "            try:  \n",
    "                # delete the corrupted packets (PAYLOADSIZE + 2B pesudo sequence number)\n",
    "                df = df[df.payload.apply(lambda x: len(x)==((PAYLOADSIZE)*3-1))]\n",
    "                df.reset_index(inplace=True)\n",
    "                # replace the resettable seq number to unresettable, for the purpose of reliability calculation\n",
    "                test = replace_seq(df.copy(), MAX_SEQ=256)\n",
    "                test.rename(columns = {'seq':'old_seq', 'new_seq':'seq'}, inplace = True)\n",
    "\n",
    "                file_delay = df.time_rx[len(df) - 1] - df.time_rx[0]\n",
    "                file_delay_s = np.timedelta64(file_delay, \"ms\").astype(int) / 1000\n",
    "                ber, error, file_content, etx = compute_ber(test, PACKET_LEN=NUM_16RND*2, MAX_SEQ=MAX_SEQ)\n",
    "                bit_reliability = (1-ber)*100\n",
    "                dis_carrier_tag = data[\"d1\"]/100 # cm -> m\n",
    "                dis_tag_rx = data[\"d2\"]/100 # cm -> m\n",
    "                dis_metric = dis_carrier_tag**2*dis_tag_rx**2\n",
    "                rssi = sum([x for x in df['rssi']])/len(df)\n",
    "\n",
    "                etx_lst.append(etx)\n",
    "                file_delay_s_lst.append(file_delay_s)\n",
    "                bit_reliability_lst.append(bit_reliability)\n",
    "                dis_metric_lst.append(dis_metric)\n",
    "                rssi_lst.append(rssi)\n",
    "            except Exception as e:\n",
    "                experiment_error = True\n",
    "                errors.append((data[\"file\"], \"\".join(traceback.format_exception(type(e), e, e.__traceback__))))\n",
    "\n",
    "        avg_etx = avg(etx_lst)\n",
    "        avg_file_delay_s = avg(file_delay_s_lst)\n",
    "        avg_bit_reliability = avg(bit_reliability_lst)\n",
    "        avg_dis_metric = avg(dis_metric_lst)\n",
    "        avg_rssi = avg(rssi_lst)\n",
    "\n",
    "        del data[\"dfs\"] # do not save log file dataframes to CSV\n",
    "        experiments = pd.concat([pd.DataFrame(data, index=[idx]), experiments])\n",
    "        experiments.loc[idx, \"etx\"] = avg_etx\n",
    "        experiments.loc[idx, \"file_delay_s\"] = avg_file_delay_s\n",
    "        experiments.loc[idx, \"bit_reliability\"] = avg_bit_reliability\n",
    "        experiments.loc[idx, \"dis_metric\"] = avg_dis_metric\n",
    "        experiments.loc[idx, \"avg_rssi\"] = avg_rssi\n",
    "        experiments.loc[idx, \"error\"] = experiment_error\n",
    "\n",
    "        if not experiment_error:\n",
    "            metrics = [avg_file_delay_s, avg_bit_reliability, avg_dis_metric]\n",
    "            radar_plot(metrics, title=f\"{data['file']} - Avg. of {data['samples']} sample(s)\")\n",
    "\n",
    "    if len(errors) > 0:\n",
    "        print(f\"{len(errors)} out of {len(experiments)} failed:\")\n",
    "        for (file, error) in errors:\n",
    "            print(f\"{file}:\\n{error}\")\n",
    "        print(\"\")\n",
    "\n",
    "    filepath = Path(f\"./results/{EXPERIMENT}.csv\")  \n",
    "    print(f\"Saving experiment data to {str(filepath)}...\")\n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "    experiments.to_csv(filepath, index=False)\n",
    "    print(\"Successfully saved.\")\n",
    "        \n",
    "if len(experiments_data) > 0:\n",
    "    analyze()\n",
    "else:\n",
    "    print(f\"No log files found in '{EXPERIMENT}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
