{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bfa30f0",
   "metadata": {},
   "source": [
    "### Turbo Analyzer script for running multiple files at once\n",
    "A csv file will be stored in '../results/<EXPERIMENT>.csv'.\n",
    "The turbo analyzer can also evaluate the average of a specific experiment, i.e.,\n",
    "you run an experiment with the same parameters multiple times and store them in\n",
    "a sub-folder of the targeted folder. \n",
    "\n",
    "The folder should have the same naming format as normal log files, but of course\n",
    "without the \".txt\" suffix. Files inside this folder can have any name, but \n",
    "must be suffixed with \".txt\".\n",
    "\n",
    "You will find the results printed as a dataframe at the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b48b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the name of the experiment folder in logs/, .e.g 'SR1'\n",
    "EXPERIMENT = \"rtx-fec-test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b884982-520f-4d73-9e58-1d5114b1c0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading experiment folder './logs/rtx-fec-test'...\n",
      "1 out of 1 failed:\n",
      "50_5_54_52_42k_fec_rtx:\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/j0/5pzb_3w57tj__yc0ry0gzczh0000gn/T/ipykernel_33691/641085485.py\", line 113, in analyze\n",
      "    raise Exception(f\"All packets are corrupt! Expected payload length of {expected_payload_len}, but got {payload_lens}\")\n",
      "Exception: All packets are corrupt! Expected payload length of 14, but got {17}\n",
      "\n",
      "\n",
      "                     file  d2  d1   a   b   baud  delta_fsk file_delay_s bit_reliability dis_metric etx misses avg_rssi    ecc   fec  retransmission  samples  error\n",
      "0  50_5_54_52_42k_fec_rtx  50   5  54  52  42000   44.51567            0               0          0   0      0        0  False  True            True        1   True\n",
      "Saving experiment data to results/rtx-fec-test.csv...\n",
      "Successfully saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import traceback\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import NaN\n",
    "from functions import * # import functions from the .py file\n",
    "from pylab import rcParams\n",
    "rcParams[\"figure.figsize\"] = 16, 4\n",
    "\n",
    "clock = 125\n",
    "logdir = f\"./logs/{EXPERIMENT}\"\n",
    "experiments_data = []\n",
    "\n",
    "print(f\"Reading experiment folder '{logdir}'...\")\n",
    "for idx, path in enumerate(glob.glob(f\"{logdir}/*\")):\n",
    "    log_paths = []\n",
    "    # We have multiple log files for this configuration and we want to \n",
    "    # read them all and get the average. \n",
    "    if os.path.isdir(path):\n",
    "        log_paths = glob.glob(f\"{path}/*.txt\")\n",
    "    elif path.endswith(\".txt\"):\n",
    "        log_paths.append(path)\n",
    "\n",
    "    if len(log_paths) == 0:\n",
    "        continue\n",
    "\n",
    "    filename = os.path.basename(path)\n",
    "    params = filename.removesuffix(\".txt\").split(\"_\")\n",
    "\n",
    "    use_fec = params[5].lower() == \"fec\" if len(params) >= 6 else False\n",
    "    use_retransmission = False\n",
    "    if len(params) > 6 and use_fec:\n",
    "        use_retransmission = params[6].lower() == \"rtx\"\n",
    "\n",
    "    dfs = [readfile(f, USE_RETRANSMISSION=use_retransmission) for f in log_paths]        \n",
    "\n",
    "    experiments_data.append({\n",
    "        \"file\": filename,\n",
    "        \"d2\":int(params[0]), # tag to receiver (cm)\n",
    "        \"d1\":int(params[1]), # carrier to tag (cm)\n",
    "        \"a\": int(params[2]),\n",
    "        \"b\": int(params[3]),\n",
    "        \"baud\": int(params[4].replace('k', '000')),\n",
    "        \"delta_fsk\": ((clock/int(params[3]) - clock/int(params[2])) * 1000)/2, # khz\n",
    "        \"file_delay_s\": None,\n",
    "        \"bit_reliability\": None,\n",
    "        \"dis_metric\": None,\n",
    "        \"etx\": None,\n",
    "        \"misses\": None,\n",
    "        \"avg_rssi\": None,\n",
    "        \"ecc\": params[5].lower() == \"ecc\" if len(params) >= 6 else False,\n",
    "        \"fec\": use_fec,\n",
    "        \"retransmission\": use_retransmission, \n",
    "        \"samples\": len(dfs),\n",
    "        \"error\": False,\n",
    "        \"dfs\": dfs,\n",
    "    })\n",
    "\n",
    "def avg(lst):\n",
    "    if len(lst) == 0:\n",
    "        return 0\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "def analyze():\n",
    "    errors = []\n",
    "    experiments = pd.DataFrame()\n",
    "\n",
    "    # codes_hex = [format(int(\"\".join([str(bit) for bit in code]), base=2), \"04X\") for code in walsh_codes]\n",
    "    # print(codes_hex)\n",
    "    # print(walsh_codes)\n",
    "\n",
    "    for idx, data in enumerate(experiments_data):\n",
    "        etx_lst = []\n",
    "        misses_lst = []\n",
    "        file_delay_s_lst = []\n",
    "        bit_reliability_lst = []\n",
    "        dis_metric_lst = []\n",
    "        rssi_lst = []\n",
    "        experiment_error = False\n",
    "        use_ecc = data[\"ecc\"]\n",
    "        use_fec = data[\"fec\"]\n",
    "\n",
    "        for df in data[\"dfs\"]:\n",
    "            try:\n",
    "                PAYLOADSIZE = 14\n",
    "                NUM_16RND = int((PAYLOADSIZE-2) // 2) # how many 16 bits random number included in each frame\n",
    "                if use_ecc:\n",
    "                    PAYLOADSIZE = 12*3+2\n",
    "                    NUM_16RND = int(((PAYLOADSIZE-2)/3) // 2) # how many 16 bits random number included in each frame\n",
    "                elif use_fec:\n",
    "                    PAYLOADSIZE = 6\n",
    "                    # 4 packets needed to get a full sample, but we index by single 16-bit samples.\n",
    "                    NUM_16RND = 1\n",
    "                # if PAYLOADSIZE % 2 != 0:\n",
    "                #     print(\"Alarm! the payload size is not even.\")\n",
    "\n",
    "                MAX_SEQ = 256 # (decimal) maximum seq number defined by the length of the seq, the length of seq is 1B\n",
    "\n",
    "                payload_lens = set()\n",
    "                expected_payload_len = (PAYLOADSIZE*3)-1\n",
    "                for x in df.payload:\n",
    "                    payload_lens.add(len(x))\n",
    "\n",
    "                # delete the corrupted packets\n",
    "                df = df[df.payload.apply(lambda x: len(x)==expected_payload_len)]\n",
    "                df.reset_index(inplace=True)\n",
    "\n",
    "                if len(df) == 0:\n",
    "                    raise Exception(f\"All packets are corrupt! Expected payload length of {expected_payload_len}, but got {payload_lens}\")\n",
    "\n",
    "                # replace the resettable seq number to unresettable, for the purpose of reliability calculation\n",
    "                (test, test_rtx) = replace_seq(df.copy(), MAX_SEQ=256)\n",
    "                test.rename(columns = {'seq':'old_seq', 'new_seq':'seq'}, inplace = True)\n",
    "                test_rtx.rename(columns = {'seq':'old_seq', 'new_seq':'seq'}, inplace = True)\n",
    "\n",
    "                file_delay = df.time_rx[len(df) - 1] - df.time_rx[0]\n",
    "                file_delay_s = np.timedelta64(file_delay, \"ms\").astype(int) / 1000\n",
    "\n",
    "                ber, error, etx, misses = compute_ber(test, test_rtx, PACKET_LEN=NUM_16RND*2, MAX_SEQ=MAX_SEQ, USE_ECC=use_ecc, USE_FEC=use_fec)\n",
    "                bit_reliability = (1 - ber) * 100\n",
    "                dis_carrier_tag = data[\"d1\"] / 100 # cm -> m\n",
    "                dis_tag_rx = data[\"d2\"] / 100 # cm -> m\n",
    "                dis_metric = dis_carrier_tag**2 * dis_tag_rx**2\n",
    "                rssi = sum([x for x in df['rssi']])/len(df)\n",
    "\n",
    "                etx_lst.append(etx)\n",
    "                misses_lst.append(misses)\n",
    "                file_delay_s_lst.append(file_delay_s)\n",
    "                bit_reliability_lst.append(bit_reliability)\n",
    "                dis_metric_lst.append(dis_metric)\n",
    "                rssi_lst.append(rssi)\n",
    "            except Exception as e:\n",
    "                experiment_error = True\n",
    "                errors.append((data[\"file\"], \"\".join(traceback.format_exception(type(e), e, e.__traceback__))))\n",
    "\n",
    "        avg_etx = avg(etx_lst)\n",
    "        avg_misses = avg(misses_lst)\n",
    "        avg_file_delay_s = avg(file_delay_s_lst)\n",
    "        avg_bit_reliability = avg(bit_reliability_lst)\n",
    "        avg_dis_metric = avg(dis_metric_lst)\n",
    "        avg_rssi = avg(rssi_lst)\n",
    "\n",
    "        del data[\"dfs\"] # do not save log file dataframes to CSV\n",
    "        experiments = pd.concat([pd.DataFrame(data, index=[idx]), experiments])\n",
    "        experiments.loc[idx, \"etx\"] = avg_etx\n",
    "        experiments.loc[idx, \"misses\"] = avg_misses\n",
    "        experiments.loc[idx, \"file_delay_s\"] = avg_file_delay_s\n",
    "        experiments.loc[idx, \"bit_reliability\"] = avg_bit_reliability\n",
    "        experiments.loc[idx, \"dis_metric\"] = avg_dis_metric\n",
    "        experiments.loc[idx, \"avg_rssi\"] = avg_rssi\n",
    "        experiments.loc[idx, \"error\"] = experiment_error\n",
    "\n",
    "        if not experiment_error:\n",
    "            metrics = [avg_file_delay_s, avg_bit_reliability, avg_dis_metric]\n",
    "            radar_plot(metrics, title=f\"{data['file']} - Avg. of {data['samples']} sample(s)\")\n",
    "\n",
    "    if len(errors) > 0:\n",
    "        print(f\"{len(errors)} out of {len(experiments)} failed:\")\n",
    "        for (file, error) in errors:\n",
    "            print(f\"{file}:\\n{error}\")\n",
    "        print(\"\")\n",
    "\n",
    "    print(experiments.to_string())\n",
    "\n",
    "    filepath = Path(f\"./results/{EXPERIMENT}.csv\")  \n",
    "    print(f\"Saving experiment data to {str(filepath)}...\")\n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "    experiments.to_csv(filepath, index=False)\n",
    "    print(\"Successfully saved.\")\n",
    "\n",
    "if len(experiments_data) > 0:\n",
    "    analyze()\n",
    "else:\n",
    "    print(f\"No log files found in '{EXPERIMENT}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
